{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fed2ba8-744d-4fcf-af2f-7a3f617e38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import speech_recognition as spr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a47bd1c-8ab0-44bb-bd97-afb542f416b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\vmuku\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: pydub in c:\\users\\vmuku\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d00a5836-de22-4bcc-abfd-691e42aadd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(fileName,mfcc,chroma,mel):\n",
    "    with sf.SoundFile(fileName) as file:\n",
    "        sound = file.read(dtype='float32')\n",
    "        sample_rate = file.samplerate     \n",
    "        if chroma:         \n",
    "            stft = np.abs(librosa.stft(sound))\n",
    "        feature = np.array([])               \n",
    "        if mfcc:\n",
    "            mfcc = np.mean(librosa.feature.mfcc(y=sound,sr=sample_rate,n_mfcc=40).T,axis=0)\n",
    "            feature =np.hstack((feature,mfcc))\n",
    "        if chroma:\n",
    "            chroma =  np.mean(librosa.feature.chroma_stft(S=stft,sr=sample_rate).T,axis=0)\n",
    "            feature = np.hstack((feature,chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(y=sound,sr=sample_rate).T,axis=0)\n",
    "            feature =np.hstack((feature,mel))\n",
    "        return feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa9d1a7-8697-49e1-abc1-bace8dff85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_emotion = {\"01\": \"neutral\", \"02\": \"calm\", \"03\": \"happy\", \"04\": \"sad\",\"05\": \"angry\",\"06\": \"fearful\",\"07\": \"disgust\",\"08\": \"surprised\"}\n",
    "EMOTIONS = {\"happy\",\"sad\",\"neutral\",\"angry\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15b7f6b7-dbb4-435d-943d-2a8512c460cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data(test_size=0.25):\n",
    "    features, emotions = [],[] #intializing features and emotions\n",
    "    for file in glob.glob(\"C:\\\\Users\\\\vmuku\\\\OneDrive\\\\Desktop\\Data science\\\\data\\\\actor_*\\\\*.wav\"):\n",
    "        fileName = os.path.basename(file)  \n",
    "        emotion = int_emotion[fileName.split(\"-\")[2]] \n",
    "        if emotion not in EMOTIONS:\n",
    "            continue\n",
    "        feature=feature_extraction(file,mfcc=True,chroma=True,mel=True,) \n",
    "        features.append(feature)\n",
    "        emotions.append(emotion)\n",
    "    return train_test_split(np.array(features),emotions, test_size=test_size, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6b88e95-9335-4a8b-84ef-3b465377106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_data(test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1327b0d7-43e8-4b30-822e-342f93a11300",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(400,), learning_rate='adaptive', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b415fc7a-bd39-4949-bdc5-fa94b55b2f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(400,),\n",
       "              learning_rate='adaptive', max_iter=1000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d23790a-3b69-4eb9-9ef0-de0afc4c0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "703c4c3e-b10a-4bc7-9bac-97988c4a9bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talking by the door\n",
      "kids talking by the door\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [102]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m audio_data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrecord(source)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men-IN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(text)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mUnknownValueError:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py:845\u001b[0m, in \u001b[0;36mRecognizer.recognize_google\u001b[1;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecognition connection failed: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e\u001b[38;5;241m.\u001b[39mreason))\n\u001b[1;32m--> 845\u001b[0m response_text \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    847\u001b[0m \u001b[38;5;66;03m# ignore any blank blocks\u001b[39;00m\n\u001b[0;32m    848\u001b[0m actual_result \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:470\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[1;32m--> 470\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readall_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    473\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:577\u001b[0m, in \u001b[0;36mHTTPResponse._readall_chunked\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m         chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    579\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:560\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# toss the CRLF at the end of the chunk\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:520\u001b[0m, in \u001b[0;36mHTTPResponse._read_next_chunk_size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\vmuku\\\\OneDrive\\\\Desktop\\\\Data science\\\\data'\n",
    "r = sr.Recognizer()\n",
    "filelist = []\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "\tfor file in files:\n",
    "       \n",
    "\t\tfilelist.append(os.path.join(root,file))\n",
    "\n",
    "\n",
    "for name in filelist:\n",
    "    with sr.AudioFile(name) as source:\n",
    "        audio_data = r.record(source)\n",
    "        try:\n",
    "            text = r.recognize_google(audio_data, language=\"en-IN\")\n",
    "            print(text)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Google Speech Recognition could not understand audio\")\n",
    "            \n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1419575-ef6d-4251-a897-bacca63503f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.698019801980198"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea656cb9-3f74-4400-b052-aaacd414cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"model\"): \n",
    "   os.mkdir(\"model\") \n",
    "pickle.dump(model, open(\"model/mlp_classifier.model\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
